<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MSTV Time-Synced Player</title>
  <meta name="viewport" content="width=device-width, initial-1" />
  <style>
    html, body {
      margin: 0; padding: 0;
      height: 100%;
      background: #000;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    #player {
      width: 100vw;
      height: 100vh;
      position: relative;
      background: #000;
    }
    video {
      width: 100%;
      height: 100%;
      background: #000;
      display: block;
    }
    #speakerIcon {
      position: absolute;
      top: 16px;
      right: 16px;
      font-size: 24px;
      color: white;
      background: rgba(0, 0, 0, 0.6);
      padding: 8px;
      border-radius: 50%;
      cursor: pointer;
      z-index: 10;
    }
    #loadingOverlay {
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      background-color: rgba(0, 0, 0, 0.8);
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      z-index: 9;
      cursor: default;
    }
    #loadingSpinner {
      width: 60px;
      height: 60px;
      border: 6px solid gold;
      border-top: 6px solid transparent;
      border-radius: 50%;
      animation: spin 1s linear infinite;
      margin-bottom: 10px;
      display: none; /* Hidden by default, controlled by JS */
    }
    #loadingText {
      color: gold;
      font-family: sans-serif;
      font-weight: bold;
      text-align: center;
      padding: 10px;
    }
    #autoplayBlockedMessage {
        color: white;
        font-family: sans-serif;
        font-weight: bold;
        font-size: 20px;
        margin-top: 20px;
        display: none;
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.6; }
        100% { opacity: 1; }
    }
    .pulsing {
        animation: pulse 1.5s infinite;
    }
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
  </style>
</head>
<body>
<div id="player">
  <div id="speakerIcon" style="display: none;">ðŸ”ˆ</div>
  <div id="loadingOverlay">
    <div id="loadingSpinner"></div>
    <div id="loadingText">Loading stream...</div>
    <div id="autoplayBlockedMessage">Tap anywhere to play</div>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
<script>
const urlParams = new URLSearchParams(window.location.search);
const ch = urlParams.get('ch') || "1";
const playerDiv = document.getElementById('player');
const speakerIcon = document.getElementById('speakerIcon');
const loadingOverlay = document.getElementById('loadingOverlay');
const loadingText = document.getElementById('loadingText');
const loadingSpinner = document.getElementById('loadingSpinner');
const autoplayBlockedMessage = document.getElementById('autoplayBlockedMessage');

let currentIndex = -1, hlsInstance = null, videoElement = null;
let currentChannelData = null;
let awaitingUserInteraction = false; // Renamed from playAttemptNeeded for clarity

// Playlist config
const channels = {
  "4": {
    type: "timesynced",
    // Current time is Tuesday, July 15, 2025 at 10:22:38 PM AEST.
    // Set a startTime slightly in the past for immediate testing.
    startTime: "2025-07-15T22:21:00+10:00", // Adjusted for AEST
    items: [
      { url: "https://test-streams.mux.dev/x36xhzz/x36xhzz.m3u8", duration: 60 },
      { url: "https://test-streams.mux.dev/pts_shift/master.m3u8", duration: 60 },
      { url: "https://test-streams.mux.dev/issue666/playlists/cisq0gim60007xzvi505emlxx.m3u8", duration: 60 },
      { url: "https://stream.mux.com/v6GvHlJ2t5B1C6/high.m3u8", duration: 60 }
    ]
  }
};

function getNowSecondsSinceStart(startTime) {
  const now = new Date();
  const start = new Date(startTime);
  return Math.floor((now - start) / 1000);
}

function getCurrentItem(chData) {
  const elapsed = getNowSecondsSinceStart(chData.startTime);
  const totalDuration = chData.items.reduce((a, b) => a + b.duration, 0);
  const loopTime = elapsed % totalDuration;

  let sum = 0;
  for (let i = 0; i < chData.items.length; i++) {
    sum += chData.items[i].duration;
    if (loopTime < sum) {
      return { index: i, offset: loopTime - (sum - chData.items[i].duration) };
    }
  }
  return { index: 0, offset: 0 };
}

function showLoadingState(message = "Loading stream...", showSpinner = true, isAutoplayBlocked = false) {
    loadingOverlay.style.display = 'flex';
    loadingText.textContent = message;
    loadingText.style.color = isAutoplayBlocked ? 'white' : 'gold'; // Text color for autoplay message

    loadingSpinner.style.display = showSpinner ? 'block' : 'none';

    autoplayBlockedMessage.style.display = isAutoplayBlocked ? 'block' : 'none';
    if (isAutoplayBlocked) {
        autoplayBlockedMessage.classList.add('pulsing');
        loadingOverlay.style.cursor = 'pointer';
    } else {
        autoplayBlockedMessage.classList.remove('pulsing');
        loadingOverlay.style.cursor = 'default';
    }
    // Clear previous click listener if not an autoplay block state
    if (!isAutoplayBlocked) {
        loadingOverlay.onclick = null;
    }
}

function hideLoadingState() {
    loadingOverlay.style.display = 'none';
    speakerIcon.style.display = 'block'; // Show speaker icon when video is playing
    autoplayBlockedMessage.style.display = 'none';
    autoplayBlockedMessage.classList.remove('pulsing');
    loadingOverlay.onclick = null;
    loadingOverlay.style.cursor = 'default';
}

function handleAutoplayBlocked(video) {
    awaitingUserInteraction = true;
    showLoadingState("Tap anywhere to play", false, true); // Hide spinner, show as autoplay blocked
    
    // Ensure the general loading overlay is the clickable area
    loadingOverlay.onclick = async () => {
        try {
            await video.play();
            console.log("User initiated playback successfully.");
            hideLoadingState();
            awaitingUserInteraction = false; // Reset flag
        } catch (e) {
            console.error("User play attempt failed:", e);
            showLoadingState("Error playing video. Tap to retry.", false, true);
        }
    };
}


async function attemptPlay(video, offset) {
  if (!video || awaitingUserInteraction) return;

  const ensureReady = () => new Promise(resolve => {
    // Check if ready state is already sufficient
    if (video.readyState >= video.HAVE_CURRENT_DATA) { // HAVE_CURRENT_DATA or higher
      resolve();
    } else {
      const onCanPlay = () => {
        video.removeEventListener('canplaythrough', onCanPlay); // More robust state
        video.removeEventListener('canplay', onCanPlay);
        video.removeEventListener('loadedmetadata', onCanPlay);
        resolve();
      };
      video.addEventListener('canplaythrough', onCanPlay, { once: true });
      video.addEventListener('canplay', onCanPlay, { once: true });
      video.addEventListener('loadedmetadata', onCanPlay, { once: true });

      // Fallback timeout to prevent infinite wait if event doesn't fire for some reason
      setTimeout(() => {
        if (video.readyState >= video.HAVE_CURRENT_DATA) resolve();
      }, 3000); // Wait up to 3 seconds for readiness
    }
  });

  try {
    showLoadingState("Buffering stream...", true); // Show spinner while buffering
    await ensureReady();
    console.log(`Video readyState after ensureReady: ${video.readyState}, duration: ${video.duration}`);

    if (video.duration > offset && !isNaN(video.duration)) { // Check for NaN to be safe
        video.currentTime = offset;
        console.log(`Attempting to seek to ${offset.toFixed(2)}s.`);
    } else {
        console.warn(`Cannot seek to offset ${offset.toFixed(2)}s. Video duration: ${video.duration}. Playing from start.`);
    }

    await video.play();
    console.log("Initial autoplay attempt successful.");
    // 'playing' event listener will handle hiding the overlay
  } catch (e) {
    console.warn("Autoplay was prevented or failed:", e);
    handleAutoplayBlocked(video);
  }
}


function setupVideoEvents(video, chData, itemIndex, offset) {
    // Listener for when video actually starts playing
    video.addEventListener('playing', () => {
        console.log("Video 'playing' event fired. Hiding overlay.");
        hideLoadingState();
    });

    // Listener for when video ends naturally
    video.addEventListener('ended', () => {
        console.log("Video ended. Preparing to play next item.");
        // Force re-evaluation to get the *next* item in sequence
        playVideo(chData, true);
    });

    // Error handling for the video element itself
    video.addEventListener('error', (e) => {
        console.error('Video element error:', e.message || e.code || e);
        showLoadingState("Video playback error.", false, false);
        loadingText.style.color = 'red';
    });

    // HLS.js specific events
    if (hlsInstance) {
        hlsInstance.on(Hls.Events.MANIFEST_PARSED, () => {
            console.log("HLS MANIFEST_PARSED. Attempting to play.");
            attemptPlay(video, offset);
        });
        hlsInstance.on(Hls.Events.ERROR, (event, data) => {
            console.error('HLS.js error:', data.details || data.type, data);
            showLoadingState(`Stream error: ${data.details || data.type}`, false, false);
            loadingText.style.color = 'red';
        });
        hlsInstance.on(Hls.Events.BUFFER_APPENDING, () => {
            // Optional: You can use this for more granular buffering feedback
            // if (!awaitingUserInteraction && loadingOverlay.style.display !== 'none') {
            //    showLoadingState("Buffering...");
            // }
        });
    } else if (video.canPlayType('application/vnd.apple.mpegurl')) {
        // Native HLS playback
        video.addEventListener("loadedmetadata", () => {
            console.log("Native HLS loadedmetadata. Attempting to play.");
            attemptPlay(video, offset);
        }, { once: true });
    }
}


function playVideo(chData, forceReplay = false) {
  const { index, offset } = getCurrentItem(chData);

  // If same item and not forced, only check for drift, unless user interaction is pending
  // Also, don't return if videoElement is null (initial load) or already ended
  if (videoElement && index === currentIndex && !forceReplay && !awaitingUserInteraction && !videoElement.ended) {
      if (!videoElement.paused) { // Only check drift if currently playing
          const expectedTime = offset;
          const currentTime = videoElement.currentTime;
          const drift = Math.abs(currentTime - expectedTime);

          if (drift > 2) {
              console.log(`Time drift detected: ${drift.toFixed(2)}s. Re-seeking to ${expectedTime.toFixed(2)}s.`);
              videoElement.currentTime = expectedTime;
          }
      }
      return; // No need to load a new video
  }

  // --- New video item or forced reload (due to 'ended' event or drift forcing new load) ---
  currentIndex = index;
  const item = chData.items[index];
  console.log(`Loading new video: ${item.url} at offset ${offset.toFixed(2)}s (item index: ${index})`);

  // Cleanup existing video and HLS instance
  if (videoElement) {
    videoElement.remove();
    videoElement = null;
  }
  if (hlsInstance) {
    hlsInstance.destroy();
    hlsInstance = null;
  }

  awaitingUserInteraction = false; // Reset flag for new video load
  showLoadingState("Loading stream...", true, false); // Show initial loading spinner/text
  speakerIcon.style.display = "none"; // Hide speaker icon during loading

  const video = document.createElement("video");
  video.autoplay = false; // We'll manually call play()
  video.playsInline = true;
  video.muted = true; // Start muted
  video.controls = false;
  videoElement = video;

  playerDiv.prepend(video); // Add video to the beginning of playerDiv

  // Mute toggle for the newly created video element
  speakerIcon.onclick = () => {
    if (videoElement) {
      videoElement.muted = !videoElement.muted;
      speakerIcon.textContent = videoElement.muted ? "ðŸ”ˆ" : "ðŸ”‡";
    }
  };

  setupVideoEvents(video, chData, index, offset); // Setup listeners for the new video

  // Load the HLS source
  if (Hls.isSupported()) {
    hlsInstance = new Hls();
    hlsInstance.loadSource(item.url);
    hlsInstance.attachMedia(video);
  } else if (video.canPlayType('application/vnd.apple.mpegurl')) {
    video.src = item.url;
  } else {
    console.error("HLS is not supported and native playback failed.");
    showLoadingState("Your browser does not support HLS playback.", false, false);
    loadingText.style.color = 'red';
  }
}

// Main logic
currentChannelData = channels[ch];
if (!currentChannelData || currentChannelData.type !== "timesynced") {
  showLoadingState(`Invalid or unsupported channel: ${ch}`, false, false);
  loadingText.style.color = 'white';
} else {
  playVideo(currentChannelData);
  // Keep the interval primarily for time synchronization (to handle drift)
  // The 'ended' event is now the main driver for next video.
  setInterval(() => {
    // Only call playVideo if we need to re-evaluate (e.g., drift correction, or if user interaction is pending)
    if (awaitingUserInteraction || (videoElement && !videoElement.ended && Math.abs(videoElement.currentTime - getCurrentItem(currentChannelData).offset) > 2)) {
      console.log("Interval re-evaluating playVideo for drift or pending interaction.");
      playVideo(currentChannelData);
    }
  }, 1000);
}
</script>
</body>
</html>
